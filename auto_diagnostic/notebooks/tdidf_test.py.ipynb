{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = ['As frases de tópico são semelhantes às declarações de mini tese.\\\n",
    "        Como uma declaração de tese, um tópico frasal tem um \\\n",
    "        ponto principal. Considerando que a tese é o ponto principal do ensaio',\\\n",
    "        'o tópico frasal é o ponto principal do parágrafo.\\\n",
    "        Como a declaração de tese, um tópico frasal tem uma função unificadora. \\\n",
    "        Mas uma declaração de tese ou frase de tópico por si só não garante unidade.', \\\n",
    "        'Um ensaio é unificado se todos os parágrafos se relacionam com a tese,\\\n",
    "        um parágrafo é unificado se todas as sentenças se relacionam com o tópico frasal while.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# processando os dados\n",
    "sentences = []\n",
    "word_set= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aizen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_Stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sent in text:\n",
    "    x = [i.lower() for  i in word_tokenize(sent) if i.isalpha()]\n",
    "    #x = [word for word in x if word not in set_Stopwords]\n",
    "    sentences.append(x)\n",
    "    for word in x:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'frases',\n",
       " 'de',\n",
       " 'tópico',\n",
       " 'são',\n",
       " 'semelhantes',\n",
       " 'às',\n",
       " 'declarações',\n",
       " 'mini',\n",
       " 'tese',\n",
       " 'como',\n",
       " 'uma',\n",
       " 'declaração',\n",
       " 'um',\n",
       " 'frasal',\n",
       " 'tem',\n",
       " 'ponto',\n",
       " 'principal',\n",
       " 'considerando',\n",
       " 'que',\n",
       " 'a',\n",
       " 'é',\n",
       " 'o',\n",
       " 'do',\n",
       " 'ensaio',\n",
       " 'parágrafo',\n",
       " 'função',\n",
       " 'unificadora',\n",
       " 'mas',\n",
       " 'ou',\n",
       " 'frase',\n",
       " 'por',\n",
       " 'si',\n",
       " 'só',\n",
       " 'não',\n",
       " 'garante',\n",
       " 'unidade',\n",
       " 'unificado',\n",
       " 'se',\n",
       " 'todos',\n",
       " 'os',\n",
       " 'parágrafos',\n",
       " 'relacionam',\n",
       " 'com',\n",
       " 'todas',\n",
       " 'sentenças',\n",
       " 'while']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'as',\n",
       " 'com',\n",
       " 'como',\n",
       " 'considerando',\n",
       " 'de',\n",
       " 'declaração',\n",
       " 'declarações',\n",
       " 'do',\n",
       " 'ensaio',\n",
       " 'frasal',\n",
       " 'frase',\n",
       " 'frases',\n",
       " 'função',\n",
       " 'garante',\n",
       " 'mas',\n",
       " 'mini',\n",
       " 'não',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'parágrafo',\n",
       " 'parágrafos',\n",
       " 'ponto',\n",
       " 'por',\n",
       " 'principal',\n",
       " 'que',\n",
       " 'relacionam',\n",
       " 'se',\n",
       " 'semelhantes',\n",
       " 'sentenças',\n",
       " 'si',\n",
       " 'são',\n",
       " 'só',\n",
       " 'tem',\n",
       " 'tese',\n",
       " 'todas',\n",
       " 'todos',\n",
       " 'tópico',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'unidade',\n",
       " 'unificado',\n",
       " 'unificadora',\n",
       " 'while',\n",
       " 'às',\n",
       " 'é'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set(word_set)\n",
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "worrd_set_clean = [word for word in word_set if word not in set_Stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unificadora',\n",
       " 'ensaio',\n",
       " 'declarações',\n",
       " 'declaração',\n",
       " 'frases',\n",
       " 'função',\n",
       " 'tese',\n",
       " 'semelhantes',\n",
       " 'principal',\n",
       " 'unificado',\n",
       " 'parágrafos',\n",
       " 'frase',\n",
       " 'tópico',\n",
       " 'mini',\n",
       " 'while',\n",
       " 'sentenças',\n",
       " 'frasal',\n",
       " 'garante',\n",
       " 'parágrafo',\n",
       " 'todos',\n",
       " 'considerando',\n",
       " 'relacionam',\n",
       " 'todas',\n",
       " 'unidade',\n",
       " 'si',\n",
       " 'ponto']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worrd_set_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(sentences)\n",
    "total_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_dict = {}\n",
    "\n",
    "i=0\n",
    "for word in word_set:\n",
    "        index_dict[word] = i\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unificadora': 0,\n",
       " 'ensaio': 1,\n",
       " 'declarações': 2,\n",
       " 'declaração': 3,\n",
       " 'frases': 4,\n",
       " 'função': 5,\n",
       " 'tese': 6,\n",
       " 'semelhantes': 7,\n",
       " 'do': 8,\n",
       " 'mas': 9,\n",
       " 'às': 10,\n",
       " 'principal': 11,\n",
       " 'com': 12,\n",
       " 'unificado': 13,\n",
       " 'parágrafos': 14,\n",
       " 'ou': 15,\n",
       " 'frase': 16,\n",
       " 'os': 17,\n",
       " 'tópico': 18,\n",
       " 'mini': 19,\n",
       " 'while': 20,\n",
       " 'se': 21,\n",
       " 'são': 22,\n",
       " 'sentenças': 23,\n",
       " 'a': 24,\n",
       " 'frasal': 25,\n",
       " 'garante': 26,\n",
       " 'uma': 27,\n",
       " 'por': 28,\n",
       " 'parágrafo': 29,\n",
       " 'só': 30,\n",
       " 'o': 31,\n",
       " 'todos': 32,\n",
       " 'considerando': 33,\n",
       " 'de': 34,\n",
       " 'é': 35,\n",
       " 'um': 36,\n",
       " 'que': 37,\n",
       " 'relacionam': 38,\n",
       " 'as': 39,\n",
       " 'como': 40,\n",
       " 'todas': 41,\n",
       " 'tem': 42,\n",
       " 'não': 43,\n",
       " 'unidade': 44,\n",
       " 'si': 45,\n",
       " 'ponto': 46}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_dict(sentences,word_set):\n",
    "    word_count = {}\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unificadora': 1,\n",
       " 'ensaio': 2,\n",
       " 'declarações': 1,\n",
       " 'declaração': 2,\n",
       " 'frases': 1,\n",
       " 'função': 1,\n",
       " 'tese': 3,\n",
       " 'semelhantes': 1,\n",
       " 'do': 2,\n",
       " 'mas': 1,\n",
       " 'às': 1,\n",
       " 'principal': 2,\n",
       " 'com': 1,\n",
       " 'unificado': 1,\n",
       " 'parágrafos': 1,\n",
       " 'ou': 1,\n",
       " 'frase': 1,\n",
       " 'os': 1,\n",
       " 'tópico': 3,\n",
       " 'mini': 1,\n",
       " 'while': 1,\n",
       " 'se': 1,\n",
       " 'são': 1,\n",
       " 'sentenças': 1,\n",
       " 'a': 3,\n",
       " 'frasal': 3,\n",
       " 'garante': 1,\n",
       " 'uma': 2,\n",
       " 'por': 1,\n",
       " 'parágrafo': 2,\n",
       " 'só': 1,\n",
       " 'o': 3,\n",
       " 'todos': 1,\n",
       " 'considerando': 1,\n",
       " 'de': 2,\n",
       " 'é': 3,\n",
       " 'um': 3,\n",
       " 'que': 1,\n",
       " 'relacionam': 1,\n",
       " 'as': 2,\n",
       " 'como': 2,\n",
       " 'todas': 1,\n",
       " 'tem': 2,\n",
       " 'não': 1,\n",
       " 'unidade': 1,\n",
       " 'si': 1,\n",
       " 'ponto': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = count_dict(sentences,word_set)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Term Frequency\n",
    "def termfreq(document,word):\n",
    "        N= len(document)\n",
    "        ocorrencia = len([token for token in document if token==word])\n",
    "        return ocorrencia/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Inverse Document Frequency\n",
    "\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_documents/word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tf_idf(sentence):\n",
    "    tf_idf_vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "\n",
    "        value = tf*idf\n",
    "        tf_idf_vec[index_dict[word]] = value\n",
    "    return tf_idf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['as',\n",
       "  'frases',\n",
       "  'de',\n",
       "  'tópico',\n",
       "  'são',\n",
       "  'semelhantes',\n",
       "  'às',\n",
       "  'declarações',\n",
       "  'de',\n",
       "  'mini',\n",
       "  'tese',\n",
       "  'como',\n",
       "  'uma',\n",
       "  'declaração',\n",
       "  'de',\n",
       "  'tese',\n",
       "  'um',\n",
       "  'tópico',\n",
       "  'frasal',\n",
       "  'tem',\n",
       "  'um',\n",
       "  'ponto',\n",
       "  'principal',\n",
       "  'considerando',\n",
       "  'que',\n",
       "  'a',\n",
       "  'tese',\n",
       "  'é',\n",
       "  'o',\n",
       "  'ponto',\n",
       "  'principal',\n",
       "  'do',\n",
       "  'ensaio'],\n",
       " ['o',\n",
       "  'tópico',\n",
       "  'frasal',\n",
       "  'é',\n",
       "  'o',\n",
       "  'ponto',\n",
       "  'principal',\n",
       "  'do',\n",
       "  'parágrafo',\n",
       "  'como',\n",
       "  'a',\n",
       "  'declaração',\n",
       "  'de',\n",
       "  'tese',\n",
       "  'um',\n",
       "  'tópico',\n",
       "  'frasal',\n",
       "  'tem',\n",
       "  'uma',\n",
       "  'função',\n",
       "  'unificadora',\n",
       "  'mas',\n",
       "  'uma',\n",
       "  'declaração',\n",
       "  'de',\n",
       "  'tese',\n",
       "  'ou',\n",
       "  'frase',\n",
       "  'de',\n",
       "  'tópico',\n",
       "  'por',\n",
       "  'si',\n",
       "  'só',\n",
       "  'não',\n",
       "  'garante',\n",
       "  'unidade'],\n",
       " ['um',\n",
       "  'ensaio',\n",
       "  'é',\n",
       "  'unificado',\n",
       "  'se',\n",
       "  'todos',\n",
       "  'os',\n",
       "  'parágrafos',\n",
       "  'se',\n",
       "  'relacionam',\n",
       "  'com',\n",
       "  'a',\n",
       "  'tese',\n",
       "  'um',\n",
       "  'parágrafo',\n",
       "  'é',\n",
       "  'unificado',\n",
       "  'se',\n",
       "  'todas',\n",
       "  'as',\n",
       "  'sentenças',\n",
       "  'se',\n",
       "  'relacionam',\n",
       "  'com',\n",
       "  'o',\n",
       "  'tópico',\n",
       "  'frasal',\n",
       "  'while']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vec = tf_idf(sent)\n",
    "    vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        ,  0.        ,  0.01228682,  0.        ,  0.01228682,\n",
       "         0.        , -0.02615292,  0.01228682,  0.        ,  0.        ,\n",
       "         0.01228682,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.01743528,  0.01228682,\n",
       "         0.        ,  0.        ,  0.01228682,  0.        , -0.00871764,\n",
       "        -0.00871764,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.00871764,  0.        ,  0.01228682,  0.        ,\n",
       "        -0.00871764, -0.01743528,  0.01228682,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.01126292,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.01126292, -0.01598234,  0.        ,  0.        ,  0.01126292,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.01126292,  0.01126292,  0.        , -0.02397351,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.00799117,\n",
       "        -0.01598234,  0.01126292,  0.        ,  0.01126292,  0.        ,\n",
       "         0.01126292, -0.01598234,  0.        ,  0.        ,  0.        ,\n",
       "        -0.00799117, -0.00799117,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.01126292,  0.01126292,\n",
       "         0.01126292,  0.        ]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.01027436,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.02896179,  0.02896179,  0.0144809 ,\n",
       "         0.        ,  0.        ,  0.0144809 , -0.01027436,  0.        ,\n",
       "         0.0144809 ,  0.05792359,  0.        ,  0.0144809 , -0.01027436,\n",
       "        -0.01027436,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.01027436,  0.0144809 ,  0.        ,  0.        ,\n",
       "        -0.02054872, -0.02054872,  0.        ,  0.02896179,  0.        ,\n",
       "         0.        ,  0.0144809 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012286821457823163\n",
      "0.011262919669671233\n",
      "0.05792358687259491\n"
     ]
    }
   ],
   "source": [
    "for vector in vectors:\n",
    "        print(max(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7598cb7ea9dde01de882b849b5b3fab1d8679c9ba86ddaed5ab6c7288771da54"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}