{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mathe\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\auto-diagnostic-97HoTFWP-py3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mathe\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\auto-diagnostic-97HoTFWP-py3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: joblib in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.3.0/pt_core_news_sm-3.3.0-py3-none-any.whl (13.0 MB)\n",
      "     --------------------------------------- 13.0/13.0 MB 29.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (60.6.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.22.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mathe\\appdata\\local\\pypoetry\\cache\\virtualenvs\\auto-diagnostic-97hotfwp-py3.9\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.3.0\n",
      "[!] As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the full\n",
      "pipeline package name 'pt_core_news_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mathe\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\auto-diagnostic-97HoTFWP-py3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "text = ['As frases de tópico são semelhantes às declarações de mini tese.\\\n",
    "        Como uma declaração de tese, um tópico frasal tem um \\\n",
    "        ponto principal. Considerando que a tese é o ponto principal do ensaio',\\\n",
    "        'o tópico frasal é o ponto principal do parágrafo.\\\n",
    "        Como a declaração de tese, um tópico frasal tem uma função unificadora. \\\n",
    "        Mas uma declaração de tese ou frase de tópico por si só não garante unidade.', \\\n",
    "        'Um ensaio é unificado se todos os parágrafos se relacionam com a tese,\\\n",
    "        um parágrafo é unificado se todas as sentenças se relacionam com o tópico frasal while.']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# processando os dados\n",
    "sentences = []\n",
    "word_set= []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to E:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "set_Stopwords = set(stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "for sent in text:\n",
    "    x = [i.lower() for  i in word_tokenize(sent) if i.isalpha()]\n",
    "    #x = [word for word in x if word not in set_Stopwords]\n",
    "    sentences.append(x)\n",
    "    for word in x:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a',\n 'as',\n 'com',\n 'como',\n 'considerando',\n 'de',\n 'declaração',\n 'declarações',\n 'do',\n 'ensaio',\n 'frasal',\n 'frase',\n 'frases',\n 'função',\n 'garante',\n 'mas',\n 'mini',\n 'não',\n 'o',\n 'os',\n 'ou',\n 'parágrafo',\n 'parágrafos',\n 'ponto',\n 'por',\n 'principal',\n 'que',\n 'relacionam',\n 'se',\n 'semelhantes',\n 'sentenças',\n 'si',\n 'são',\n 'só',\n 'tem',\n 'tese',\n 'todas',\n 'todos',\n 'tópico',\n 'um',\n 'uma',\n 'unidade',\n 'unificado',\n 'unificadora',\n 'while',\n 'às',\n 'é'}"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a',\n 'as',\n 'com',\n 'como',\n 'considerando',\n 'de',\n 'declaração',\n 'declarações',\n 'do',\n 'ensaio',\n 'frasal',\n 'frase',\n 'frases',\n 'função',\n 'garante',\n 'mas',\n 'mini',\n 'não',\n 'o',\n 'os',\n 'ou',\n 'parágrafo',\n 'parágrafos',\n 'ponto',\n 'por',\n 'principal',\n 'que',\n 'relacionam',\n 'se',\n 'semelhantes',\n 'sentenças',\n 'si',\n 'são',\n 'só',\n 'tem',\n 'tese',\n 'todas',\n 'todos',\n 'tópico',\n 'um',\n 'uma',\n 'unidade',\n 'unificado',\n 'unificadora',\n 'while',\n 'às',\n 'é'}"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set(word_set)\n",
    "word_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "worrd_set_clean = [word for word in word_set if word not in set_Stopwords]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "['si',\n 'garante',\n 'parágrafos',\n 'todos',\n 'ponto',\n 'unidade',\n 'unificado',\n 'principal',\n 'declarações',\n 'todas',\n 'frase',\n 'frases',\n 'tese',\n 'parágrafo',\n 'relacionam',\n 'sentenças',\n 'tópico',\n 'unificadora',\n 'ensaio',\n 'função',\n 'considerando',\n 'declaração',\n 'mini',\n 'frasal',\n 'semelhantes',\n 'while']"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worrd_set_clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(sentences)\n",
    "total_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "index_dict = {}\n",
    "\n",
    "i=0\n",
    "for word in word_set:\n",
    "        index_dict[word] = i\n",
    "        i+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "{'que': 0,\n 'mas': 1,\n 'si': 2,\n 'se': 3,\n 'garante': 4,\n 'a': 5,\n 'parágrafos': 6,\n 'todos': 7,\n 'são': 8,\n 'tem': 9,\n 'ponto': 10,\n 'unidade': 11,\n 'unificado': 12,\n 'principal': 13,\n 'por': 14,\n 'com': 15,\n 'declarações': 16,\n 'de': 17,\n 'ou': 18,\n 'todas': 19,\n 'é': 20,\n 'frase': 21,\n 'frases': 22,\n 'tese': 23,\n 'parágrafo': 24,\n 'relacionam': 25,\n 'sentenças': 26,\n 'como': 27,\n 'um': 28,\n 'tópico': 29,\n 'só': 30,\n 'as': 31,\n 'não': 32,\n 'unificadora': 33,\n 'ensaio': 34,\n 'função': 35,\n 'considerando': 36,\n 'declaração': 37,\n 'do': 38,\n 'mini': 39,\n 'o': 40,\n 'os': 41,\n 'frasal': 42,\n 'às': 43,\n 'semelhantes': 44,\n 'while': 45,\n 'uma': 46}"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def count_dict(sentences,word_set):\n",
    "    word_count = {}\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "{'que': 1,\n 'mas': 1,\n 'si': 2,\n 'se': 1,\n 'garante': 2,\n 'a': 3,\n 'parágrafos': 2,\n 'todos': 2,\n 'são': 1,\n 'tem': 2,\n 'ponto': 4,\n 'unidade': 2,\n 'unificado': 2,\n 'principal': 4,\n 'por': 1,\n 'com': 1,\n 'declarações': 2,\n 'de': 2,\n 'ou': 1,\n 'todas': 2,\n 'é': 3,\n 'frase': 2,\n 'frases': 2,\n 'tese': 6,\n 'parágrafo': 4,\n 'relacionam': 2,\n 'sentenças': 2,\n 'como': 2,\n 'um': 3,\n 'tópico': 6,\n 'só': 1,\n 'as': 2,\n 'não': 1,\n 'unificadora': 2,\n 'ensaio': 4,\n 'função': 2,\n 'considerando': 2,\n 'declaração': 4,\n 'do': 2,\n 'mini': 2,\n 'o': 3,\n 'os': 1,\n 'frasal': 6,\n 'às': 1,\n 'semelhantes': 2,\n 'while': 2,\n 'uma': 2}"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = count_dict(sentences,word_set)\n",
    "word_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Term Frequency\n",
    "def termfreq(document,word):\n",
    "        N= len(document)\n",
    "        ocorrencia = len([token for token in document if token==word])\n",
    "        return ocorrencia/N"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "#Inverse Document Frequency\n",
    "\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_documents/word_occurance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def tf_idf(sentence):\n",
    "    tf_idf_vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "\n",
    "        value = tf*idf\n",
    "        tf_idf_vec[index_dict[word]] = value\n",
    "    return tf_idf_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vec = tf_idf(sent)\n",
    "    vectors.append(vec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([ 0.01228682,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.00871764,  0.        ,  0.        ,  0.01228682,  0.        ,\n        -0.03095913,  0.        ,  0.        , -0.03095913,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.00871764,  0.        ,  0.        , -0.07702708,  0.        ,\n         0.        ,  0.        ,  0.        , -0.01743528, -0.05135139,\n         0.        ,  0.        ,  0.        ,  0.        , -0.01547956,\n         0.        ,  0.        , -0.01547956,  0.        ,  0.        ,\n        -0.00871764,  0.        , -0.02567569,  0.01228682,  0.        ,\n         0.        ,  0.        ]),\n array([ 0.        ,  0.01126292,  0.        ,  0.        ,  0.        ,\n        -0.00799117,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.0141896 ,  0.        ,  0.        , -0.0141896 ,  0.01126292,\n         0.        ,  0.        ,  0.        ,  0.01126292,  0.        ,\n        -0.00799117,  0.        ,  0.        , -0.0470721 , -0.0141896 ,\n         0.        ,  0.        ,  0.        , -0.00799117, -0.07060816,\n         0.01126292,  0.        ,  0.01126292,  0.        ,  0.        ,\n         0.        ,  0.        , -0.0283792 ,  0.        ,  0.        ,\n        -0.01598234,  0.        , -0.0470721 ,  0.        ,  0.        ,\n         0.        ,  0.        ]),\n array([ 0.        ,  0.        ,  0.        ,  0.05792359,  0.        ,\n        -0.01027436,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.02896179,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.02054872,  0.        ,  0.        , -0.03026064, -0.01824377,\n         0.        ,  0.        ,  0.        , -0.02054872, -0.03026064,\n         0.        ,  0.        ,  0.        ,  0.        , -0.01824377,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.01027436,  0.0144809 , -0.03026064,  0.        ,  0.        ,\n         0.        ,  0.        ]),\n array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.06009713,  0.        ,  0.        , -0.06009713,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        , -0.14952315,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        , -0.0996821 ,\n         0.        ,  0.        ,  0.        ,  0.        , -0.03004857,\n         0.        ,  0.        , -0.03004857,  0.        ,  0.        ,\n         0.        ,  0.        , -0.04984105,  0.        ,  0.        ,\n         0.        ,  0.        ]),\n array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.0283792 ,  0.        ,  0.        , -0.0283792 ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        , -0.09414421, -0.0283792 ,\n         0.        ,  0.        ,  0.        ,  0.        , -0.14121631,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        , -0.0567584 ,  0.        ,  0.        ,\n         0.        ,  0.        , -0.09414421,  0.        ,  0.        ,\n         0.        ,  0.        ]),\n array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        , -0.06052128, -0.03648754,\n         0.        ,  0.        ,  0.        ,  0.        , -0.06052128,\n         0.        ,  0.        ,  0.        ,  0.        , -0.03648754,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        , -0.06052128,  0.        ,  0.        ,\n         0.        ,  0.        ])]"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012286821457823163\n",
      "0.011262919669671233\n",
      "0.05792358687259491\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for vector in vectors:\n",
    "        print(max(vector))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}